data=data.frame(training$IL_11,training$IL_13,training$IL_16,training$IL_17E,training$IL_1alpha,training$IL_3,training$IL_4,training$IL_5,training$IL_6,training$IL_6_Receptor,training$IL_7,training$IL_8,training$diagnosis)
help(caret$predict)
help(predict)
help(caret.predict)
help(caret)
modelFit=train(data$diagnosis~.,method="glm",data=data)
modelFit=train(diagnosis~.,method="glm",data=data)
head(data)
dim(data)
length(data$diagnosis)
length(data$training.diagnosis)
modelFit=train(training.diagnosis~.,method="glm",data=data)
modelFit=train(data$training.diagnosis~.,method="glm",data=data)
install.packages('e1071', dependencies=TRUE)
modelFit=train(data$training.diagnosis~.,method="glm",data=data)
modelFit
modelFit
summary(modelFit)
confusionMatrix(testing$diagnosis,predict(modelFit))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50, list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
size(adDate)
dim(adData)
dim(adData$diagnosis)
dim(adData[:,1])
dim(adData[,1])
dim(adData)
type(adData)
class(adData)
adData[1,1]
adData[1,:]
adData[1,]
adData[1,1]
adData[1,22]
adData[1,2]
name(adData)
names(adData)
adData$diagnosis
length(adData$diagnosis)
dim(adData$diagnosis)
dim(training)
dim(testing)
help(createDataPartition)
trainIndex = createDataPartition(diagnosis, p = 0.50, list=T)
training = adData[trainIndex,]
testing = adData[-trainIndex,]dim(training)
trainIndex = createDataPartition(diagnosis, p = 0.50, list=F)
training = adData[trainIndex,]
testing = adData[-trainIndex,]dim(training)
trainIndex = createDataPartition(diagnosis, p = 0.50, list=F)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
qplot(CompressiveStrength,data=training)
dim(training)
training$CompressiveStrength)
training$CompressiveStrength
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(CompressiveStrength,data=training)
library(ggplot)
library(ggplot2)
qplot(CompressiveStrength,data=training)
help(gplot)
help(qplot)
a=[1 2]
a=[1;2]
a=c(1,2)
a
type(a)
class(a)
is.integer(a)
is.numeric(a)
is.matrix(a)
is.vector(a)
b=1
is.vector(b)
plot(training$CompressiveStrength)
plot(CompressiveStrength,data=training)
a=factor(1,2)
a
class(a)
class(training$FlyAsh)
help(cut2)
library(Hmisc)
install.package("Hmisc")
install.packages("Hmisc")
library(Hmisc)
help(cut2)
hist(training$FlyAsh)
test=cut2(training$FlyAsh,g=2)
size(test)
dim(test)
test
plot(training$CompressiveStrength)
plot(training$CompressiveStrength,col=test)
dim(training)
class(training)
dim(training,2)
dim(training)[2]
help(source)
print(2)
for i in 1:dim(training)[2] {
print(class(training[,i]))
}
for (i in 1:dim(training)[2]) {
print(class(training[,i]))
}
training
training[,2]
class(training[,2])
vector()
class(2)
class(2.)
class(int(2)
)
class(as.integer(2))
class(integer(2))
class('2')
class(factor=(2))
factor(2)
class(factor(2))
2L
class(2L)
attributes(2)
a=2
attributes(a)
attributes(training)
nams(trainnig)
names(trainin)
names(training)
class(TRUE)
class(1)
class(logical(1))
logical(1)
logical(0)
logical(2)
as.logical(2)
as.logical(0)
class(1+1i)
m=matrix(1:10)
m
class(m)
attributes(m)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
source(ex3.r)
getwd()
source(ex3.r,local="D:Mes Documents/Coursera/Practical Machine Learning")
source(ex3.r,local="D:Mes Documents/Coursera/Practical Machine Learning/")
hist(training$SuperPlasticizer)
class(training$SuperPlasticizer)
dim(training)
names(training)
hist(training$Superplasticizer)
hist(log(training$Superplasticizer)
)
sum(training$Superplasticizer<0)
sum(training$Superplasticizer=0)
sum(training$Superplasticizer==0)
log(0)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
dim(training)
names(traiing)
names(training)
dim(training) #131 colonnes
names(training) #12 variables qui comment par IL
X = training[,58:69]
pca=preProcess(X,method="pca")
pca
summary(pca)
print(pca)
pca=preProcess(X,method="pca",thresh=0.85)
print(pca)
pca=preProcess(X,method="pca",thresh=0.9)
summary(pca)
print(pca)
dim(training) #131 colonnes
names(training) #12 variables qui comment par IL
X = data.frame(training[,58:69],training$diagnosis)
names(X)
X = data.frame(training[,58:69],diagnosis=training$diagnosis)
names(X)
train(diagnosis~.,data=X,method="glm")
modelFit=train(diagnosis~.,data=X,method="glm")
predict(modelFit,newdata=test)
predict(modelFit,newdata=testing)
testing$diagnosis
predict(modelFit,newdata=testing)==testing$diagnosis
mean(predict(modelFit,newdata=testing)==testing$diagnosis)
preProc=preProcess(X,method="pca",thresh=80)
preProc=preProcess(X[,-1],method="pca",thresh=80)
a=matrix(1:4,nrow=2)
a
a[,1]
a[,-1]
names(X)
tail(X)
preProc=preProcess(X[,-13],method="pca",thresh=80)
confusionMatrix(testing$diagnosis,predict(modelFit,newdata=testing))
preProc
class(preProc)
dim(preProc)
print(preProc)
summary(preProc)
predict(preProc,training$diagnosis)
predict(preProc,X[,-13])
trainPC = predict(preProc,X[,-13])
modelFit = train(diagnosis~.,data=trainPC,method="glm")
modelFit = train(X$diagnosis~.,data=trainPC,method="glm")
confusionMatrix(testing$diagnosis,predict(modelFit,newdata=testing))
dim(testing)
testPC=predict(PreProc,newdata=testing[,58:69])
testPC=predict(preProc,newdata=testing[,58:69])
confusionMatrix(testing$diagnosis,predict(modelFit,newdata=testPC))
help(createDataPartition)
dim(segmentationOriginal)
dim(SegmentationOriginal)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
dim(SegmentationOriginal)
dim(segmentationOriginal)
names(segmentationOriginal)
inTrain = createDataPartition(y=segmentationOriginal$Case,p=0.5,list=F)
training = segmentationOriginal[inTrain,]
testing = segmentationOriginal[-inTrain,]
set.seed(125)
dim(training)
modFit = train(Case,data=training,method="rpart")
names(training)
names(training)=="Case"
which(names(training)=="Case")
which(names(training)=="CART")
which(names(training)=="Cart")
training$Case[1:10]
training$Case
training = segmentationOriginal[Case=='Train',]
training = segmentationOriginal[segmentationOriginal$Case=='Train',]
testing = segmentationOriginal[segmentationOriginal$Case=='Test',]
set.seed(125)
names(training)
which(training=="PS")
a
which(a==2)
training(2728)
training[2728]
a[2]
class(training)
attributes(training)
training$Cell[1:10]
names(training)
training$Case[1:5]
training$Class[1:5]
modFit = train(Class~.,data=training,method="rpart")
modFit
print(modFit$finalModel)
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
help(fancyRpartPlot)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
help(load)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
dim(olive)
library(caret)
library(rattle)
library(rpart.plot)
dim(olive)
names(olive)
modFit = train(Area~.,data=olive,method="rpart")
print(modFit)
newdata = as.data.frame(t(colMeans(olive)))
dim(newdata)
newdata
print(modFit$finalModel)
Area
olive$Area
predict(modFit,newdata=newdata)
newdata
predict(modFit,newdata=newdata[,-1])
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
names(trainSA)
help(SAheart)
help(glm)
inTrain = train(chd~alcohol+obesity+tobacco+typea+ldl,offset=age,method="glm",family="binomial",data=trainSA)
help(carret.train)
help(train)
inTrain = train(chd~alcohol obesity tobacco typea ldl,offset=age,method="glm",family="binomial",data=trainSA)
inTrain = train(chd~alcohol+obesity+tobacco+typea+ldl,offset=age,method="glm",family="binomial",data=trainSA)
inTrain = train(chd~alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
inTrain = train(chd~age,alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
set.seed(13234)
inTrain = train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
predict(inTrain,testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missclass(testSA$chd,predict(inTrain,testSA))
missClass(testSA$chd,predict(inTrain,testSA))
missClass(trainSA$chd,predict(inTrain,trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
dim(vowel.train)
names(vowel.train)
y=as.factor(vowel.train$y)
y
vowel.train$y=as.factor(vowel.train$y)
vowel.test$y=as.factor(vowel.test$y)
set.seed(33833)
inTrain = train(y~.,data="vowel.train",method="rf")
varImp(inTrain)
set.seed(33833)
inTrain = train(y~.,data=vowel.train,method="rf")
varImp(inTrain)
varImp(inTrain$finalModel)
vI <- varImp(modFit5$finalModel)
vI$sample <- row.names(vI); vI <- vI[order(vI$Overall, decreasing = T),]
vI
vI <- varImp(inTrain$finalModel)
vI$sample <- row.names(vI); vI <- vI[order(vI$Overall, decreasing = T),]
vI
set.seed(33833)
inTrain = train(y~.,data=vowel.train,method="rf")
vI <- varImp(inTrain$finalModel)
vI$sample <- row.names(vI); vI <- vI[order(vI$Overall, decreasing = T),]
vI
install.packages("rpart.plot")
install.packages("rattle")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rattle)
library(rpart.plot)
# Code Jp
inTrain = createDataPartition(y=segmentationOriginal$Case,list=F)
training = segmentationOriginal[segmentationOriginal$Case=='Train',]
testing = segmentationOriginal[segmentationOriginal$Case=='Test',]
set.seed(125)
modFit = train(Class~.,data=training,method="rpart")
print(modFit)
fancyRpartPlot(modFit$finalModel)
install.packages("rattle")
install.packages("rpart.plot")
install.packages("rpart.plot")
help(confusionMatrix)
set.seed(33833)
treeFit = train(y~.,data=vowel.train,method="rf")
gbmFit = train(y~.,data=vowel.train,method="gbm")
gbmFit = train(y~.,data=vowel.train,method="gbm",verbose=F)
confusionMatrix(predict(treeFit,vowel.test),vowel.test)
predict(treeFit,vowel.test)
confusionMatrix(predict(treeFit,vowel.test),vowel.test$y)
confusionMatrix(predict(gbmFit,vowel.test),vowel.test$y)
agree=predict(gbmFit,vowel.test)==predict(treeFit,vowel.test)
agree
mean(agree)
confusionMatrix(predict(gbmFit,vowel.test)[agree==T],vowel.test$y[agree==T])
confusionMatrix(predict(treeFit,vowel.test)[agree==T],vowel.test$y[agree==T])
set.seed(33833)
treeFit = train(y~.,data=vowel.train,method="rf")
confusionMatrix(predict(treeFit,vowel.test),vowel.test$y)
set.seed(33833)
gbmFit = train(y~.,data=vowel.train,method="gbm",verbose=F)
confusionMatrix(predict(gbmFit,vowel.test),vowel.test$y)
agree=predict(gbmFit,vowel.test)==predict(treeFit,vowel.test)
confusionMatrix(predict(gbmFit,vowel.test)[agree==T],vowel.test$y[agree==T])
treePred = predict(treeFit,testing)
set.seed(62433)
treeFit = train(diagnosis~.,data=training,method="rf")
treePred = predict(treeFit,testing)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
treeFit = train(diagnosis~.,data=training,method="rf")
treePred = predict(treeFit,testing)
treePred
gbmFit = train(diagnosis~.,data=training,method="gbm",verbose=F)
gbmPred = predict(gbmFit,testing)
ldaFit = train(diagnosis~.,data=training,method="lda")
ldaPred = predict(ldaFit,testing)
comboTrain = data.frame(treePred,gbmPred,ldaPred,diagnosis=testing$diagnosis)
comboFit = train(wage~.,method="rf",data=comboTrain)
comboFit = train(diagnosis~.,method="rf",data=comboTrain)
confusionMatrix(predict(comboFit,testing),testing)
confusionMatrix(predict(comboFit,testing),testing$diagnosis)
confusionMatrix(predict(comboFit,testing),testing$diagnosis)[1]
confusionMatrix(predict(comboFit,testing),testing$diagnosis)$Accuracy
confusionMatrix(predict(comboFit,testing),testing$diagnosis)$overall[1]
confusionMatrix(predict(treePred,testing),testing$diagnosis)$overall[1]
confusionMatrix(treePred,testing$diagnosis)$overall[1]
confusionMatrix(gbmPred,testing$diagnosis)$overall[1]
confusionMatrix(ldaPred,testing$diagnosis)$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Code Jp
set.seed(233)
modFit = train(CompressiveStrengh~.,method="lasso",data=training,trace=T)
set.seed(233)
modFit = train(CompressiveStrength~.,method="lasso",data=training,trace=T)
plot.enet(modFit$finalModel, xvar = "penalty", use.color = TRUE)
setwd("D:/Mes Documents/Coursera/Practical Machine Learning)
")"
)
)
""
setwd("D:/Mes Documents/Coursera/Practical Machine Learning")
getwd()
setwd("D:/Mes Documents/Coursera/Practical Machine Learning")
dat = read.csv("Quiz 4/gaData.csv")
dat
dim(dat)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
library(lubridate)
install.packages("lubridate")
library(lubridate)  # For year() function below
setwd("D:/Mes Documents/Coursera/Practical Machine Learning")
dat = read.csv("Quiz 4/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
modFit = bats(tstrain)
plot(tstrain)
plot(training)
install.packages("forecast")
library(forecast)
modFit = bats(tstrain)
print(modFit)
help(bats)
modFit
modFit$finalModel
plot(modFit)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
mod <- svm(CompressiveStrength ~ ., data = training)
pred <- predict(mod, testing)
sqrt((sum(pred - testing$CompressiveStrength)^2)/length(pred))
sqrt(sum((pred - testing$CompressiveStrength)^2)/length(pred))
# Code Coursera
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
# Code Jp
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
treeFit = train(y~.,data=vowel.train,method="rf")
confusionMatrix(predict(treeFit,vowel.test),vowel.test$y)
set.seed(33833)
gbmFit = train(y~.,data=vowel.train,method="gbm",verbose=F)
confusionMatrix(predict(gbmFit,vowel.test),vowel.test$y)
agree=predict(gbmFit,vowel.test)==predict(treeFit,vowel.test)
confusionMatrix(predict(gbmFit,vowel.test)[agree==T],vowel.test$y[agree==T])
confusionMatrix(predict(treeFit,vowel.test)[agree==T],vowel.test$y[agree==T])
